{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TTLrhIxWcjPK",
        "8_Q-nJTVb8gq",
        "AOnJrtGjbMUZ",
        "oY_J3RFWujFm",
        "2yM6mkpH3Wgu",
        "ZaRfF9c8qLGM",
        "MXDqkDct5gdu",
        "_L_TUKeJfNtS",
        "tTgoup3IpXMu",
        "8fV3FBts3Mj_",
        "_o6tkYjBFSjt"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhamsrivastava951/NLP/blob/main/NER_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bic10Kg2u2mh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6852356-1b0c-4f5d-a4f5-fa4391c94275"
      },
      "source": [
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        " #download data\n",
        "id = '1YnpJzqcTAwikoAzKuqKtkiXMjCphud51'\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('train.csv')\n",
        "\n",
        "id = '1NElN4SlJoimeDbV8MoV8LsBmNYAOVcDw'\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('val.csv')\n",
        "\n",
        "id = '1E2XvfBpX8OUKPdkFtmepaRguXXdttbhX'\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('test_without_labels.csv')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "\n",
        "import sys\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f5d61ccf850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HJWA48ntI75"
      },
      "source": [
        "# Data PreProcessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enHCSOd8v1PZ"
      },
      "source": [
        "#read csv fiels into pandas dataframe\n",
        "df_train= pd.read_csv(\"train.csv\")\n",
        "df_val = pd.read_csv(\"val.csv\")\n",
        "df_test = pd.read_csv(\"test_without_labels.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "oQgzEnDLwEZ8",
        "outputId": "194c7eef-5158-4bc6-e666-b9fb42fdb955"
      },
      "source": [
        "df_train.info()\n",
        "# Check for null/missing values\n",
        "print(f\"\\nNull values for training data set: {df_train.isnull().values.sum()}\")\n",
        "print(f\"\\nNull values for test data set: {df_val.isnull().values.sum()}\")\n",
        "print(f\"\\nNull values for val data set: {df_test.isnull().values.sum()}\")\n",
        "\n",
        "#check for any NAN values\n",
        "print(f\"\\nAny NAN values in Train: {df_train.isnull().values.any()}\")\n",
        "print(f\"\\nAny NAN values in Val: {df_val.isnull().values.any()}\")\n",
        "print(f\"\\nAny NAN values in test: {df_val.isnull().values.any()}\")\n",
        "\n",
        "#Shape of dataframe\n",
        "print(f\"\\n Train shape: {df_train.shape}\")\n",
        "print(f\"\\n Val shape: {df_val.shape}\")\n",
        "df_train.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 573 entries, 0 to 572\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   sents   573 non-null    object\n",
            " 1   labels  573 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 9.1+ KB\n",
            "\n",
            "Null values for training data set: 0\n",
            "\n",
            "Null values for test data set: 0\n",
            "\n",
            "Null values for val data set: 0\n",
            "\n",
            "Any NAN values in Train: False\n",
            "\n",
            "Any NAN values in Val: False\n",
            "\n",
            "Any NAN values in test: False\n",
            "\n",
            " Train shape: (573, 2)\n",
            "\n",
            " Val shape: (191, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sents</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Operation Steel Curtain ( Arabic : ا ل ح ج ا ب...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The hospital has facilities for MRI and CT sca...</td>\n",
              "      <td>B-Location I-Location O O O O O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The operation was important in that it was the...</td>\n",
              "      <td>O O O O O O O O O O O O O O B-Organisation I-O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This was my first visit to Uzbekistan and an i...</td>\n",
              "      <td>O O B-Person O O O B-Location O O O O O O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The group was founded by Sheikh Abu Omar al - ...</td>\n",
              "      <td>B-Organisation I-Organisation O O O B-Person I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>And hopefully , by reading , we can achieve th...</td>\n",
              "      <td>O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>But nobody can leave now .</td>\n",
              "      <td>O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The Members of the Security Council are encour...</td>\n",
              "      <td>B-Organisation I-Organisation I-Organisation I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Iraq</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>We extend our deepest condolences to the famil...</td>\n",
              "      <td>B-Organisation O O O O O B-Organisation I-Orga...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sents                                             labels\n",
              "0  Operation Steel Curtain ( Arabic : ا ل ح ج ا ب...  O O O O O O O O O O O O O O O O O O O O O O O ...\n",
              "1  The hospital has facilities for MRI and CT sca...  B-Location I-Location O O O O O O O O O O O O ...\n",
              "2  The operation was important in that it was the...  O O O O O O O O O O O O O O B-Organisation I-O...\n",
              "3  This was my first visit to Uzbekistan and an i...  O O B-Person O O O B-Location O O O O O O O O ...\n",
              "4  The group was founded by Sheikh Abu Omar al - ...  B-Organisation I-Organisation O O O B-Person I...\n",
              "5  And hopefully , by reading , we can achieve th...                        O O O O O O O O O O O O O O\n",
              "6                         But nobody can leave now .                                        O O O O O O\n",
              "7  The Members of the Security Council are encour...  B-Organisation I-Organisation I-Organisation I...\n",
              "8                                               Iraq                                                  O\n",
              "9  We extend our deepest condolences to the famil...  B-Organisation O O O O O B-Organisation I-Orga..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "KwdJLnEEpX1e",
        "outputId": "b9ab17bf-f126-4d36-b10a-9f7000d6180f"
      },
      "source": [
        "#Validation set\n",
        "df_val.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sents</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>For 14 - year - old Amjad it is safer there th...</td>\n",
              "      <td>O B-Quantity I-Quantity I-Quantity I-Quantity ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>. Near Al Huwayjah , one strike engaged an ISI...</td>\n",
              "      <td>O O B-Location I-Location O B-Quantity B-Weapo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Philip Hammond condemns apparent barrel bomb a...</td>\n",
              "      <td>B-Person I-Person O O B-Weapon I-Weapon O O B-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Foreign Secretary Boris Johnson welcomes the U...</td>\n",
              "      <td>B-Person I-Person I-Person I-Person O O B-Docu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sadiq stood behind Karim when the musician pla...</td>\n",
              "      <td>B-Person O O B-Person O B-Person I-Person O O ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sents                                             labels\n",
              "0  For 14 - year - old Amjad it is safer there th...  O B-Quantity I-Quantity I-Quantity I-Quantity ...\n",
              "1  . Near Al Huwayjah , one strike engaged an ISI...  O O B-Location I-Location O B-Quantity B-Weapo...\n",
              "2  Philip Hammond condemns apparent barrel bomb a...  B-Person I-Person O O B-Weapon I-Weapon O O B-...\n",
              "3  Foreign Secretary Boris Johnson welcomes the U...  B-Person I-Person I-Person I-Person O O B-Docu...\n",
              "4  Sadiq stood behind Karim when the musician pla...  B-Person O O B-Person O B-Person I-Person O O ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-qbPws7CCY0"
      },
      "source": [
        "#convert all sentences to lower in train,val and test set\n",
        "df_train['sents']=df_train['sents'].str.lower()\n",
        "df_val['sents']=df_val['sents'].str.lower()\n",
        "df_test['sents']=df_test['sents'].str.lower()\n",
        "# df_train.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j90noaor_ahj"
      },
      "source": [
        "# def remove_extra_dots(x):\n",
        "#   for sent in x:\n",
        "#     return re.sub('[.](?!\\d*$)', '',x)\n",
        "#     # return re.sub('``',\"' '\",x)\n",
        "#     #split \"  to single quotes\n",
        "\n",
        "# df_train['sents']=df_train['sents'].apply(lambda x:remove_extra_dots(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0Bj5a0owwzw",
        "outputId": "d5c3cb5d-c04c-4103-876f-efbd3c9e057f"
      },
      "source": [
        "#Creating list of sentences and labels\n",
        "sentences = df_train['sents'].tolist()\n",
        "labels= df_train['labels'].tolist()\n",
        "print(\"Training set\")\n",
        "print(f\"First Sentence: {sentences[0]}\")\n",
        "print(f\"NER Tags of first Sentence: {labels[0]}\")\n",
        "\n",
        "print(\"\\n Val set\")\n",
        "val_sentences = df_val['sents'].tolist()\n",
        "val_labels= df_val['labels'].tolist()\n",
        "print(f\"First val Sentence: {val_sentences[0]}\")\n",
        "print(f\"NER Tags of first val Sentence: {val_labels[0]}\")\n",
        "\n",
        "print(\"\\n Test set\")\n",
        "test_sentences = df_test['sents'].tolist()\n",
        "print(f\"First Test Sentence: {test_sentences[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set\n",
            "First Sentence: operation steel curtain ( arabic : ا ل ح ج ا ب ا ل ف و ل ا ذ ي al hejab elfulathi ) was a military operation executed by coalition forces in early november 2005 to reduce the flow of foreign insurgents crossing the border and joining the iraqi insurgency .\n",
            "NER Tags of first Sentence: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-Organisation I-Organisation O B-Temporal I-Temporal I-Temporal O O O O O B-Organisation I-Organisation O O O O O O B-Nationality O O\n",
            "\n",
            " Val set\n",
            "First val Sentence: for 14 - year - old amjad it is safer there than being above ground , and over time his enthusiasm for the place has earned him the role of \" \" deputy librarian \" \" . \"\n",
            "NER Tags of first val Sentence: O B-Quantity I-Quantity I-Quantity I-Quantity I-Quantity B-Person O O O O O O O O O O O O B-Person O O O O O O O O O O O O O O O O O O\n",
            "\n",
            " Test set\n",
            "First Test Sentence: carter thanked abadi for nearly two years of a close personal partnership , and noted the continued supporting role the united states and the counter - isil coalition can play in iraq ' s efforts to destroy the terrorist group , according to the release .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjaOue8eqf9H"
      },
      "source": [
        "#getting POS TAGS for each word in the sentences\n",
        "# import spacy\n",
        "# from spacy import displacy\n",
        "# import en_core_web_sm\n",
        "\n",
        "# #nlp=spacy.load('en_core_web_trf')\n",
        "# nlp = en_core_web_sm.load()\n",
        "# POS_TAGS=[]\n",
        "# D_Tags=[]\n",
        "# def get_tag(x):\n",
        "#   pTags=[]\n",
        "#   dTags=[]\n",
        "#   for words in nlp(x):\n",
        "#     pTags.append(words.tag_)\n",
        "#     dTags.append(words.dep_)\n",
        "#   POS_TAGS.append(' '.join(pTags))\n",
        "#   D_Tags.append(' '.join(dTags))\n",
        "\n",
        "# df_train['sents'].apply(lambda x: get_tag(x))\n",
        "# print(f\"First Sentence --> correspoding POS Tags: {POS_TAGS[0]}\")\n",
        "# print(f\"\\nFirst Sentences  --> correspoding Dependency Tags: {D_Tags[0]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojikD3w0tO-t"
      },
      "source": [
        "## POS Tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVv_2UQLMlOQ",
        "outputId": "e1a27dc4-9aa4-4c00-98a5-48c9ad0348ed"
      },
      "source": [
        "POS_TAGS=[]\n",
        "# D_Tags=[]\n",
        "val_POS_TAGS=[]\n",
        "test_POS_TAGS=[]\n",
        "\n",
        "#function to get POS TAGS\n",
        "def get_tag(x,POS='Train'):\n",
        "  pTags=[]\n",
        "  temp=[]\n",
        "  #nltk POS tags function\n",
        "  tags_tp_list=nltk.pos_tag(x.split())\n",
        "\n",
        "  for words,tags in tags_tp_list:\n",
        "    temp.append(tags)\n",
        "  if POS=='Test':\n",
        "    test_POS_TAGS.append(' '.join(temp))\n",
        "  elif POS=='Val':\n",
        "    val_POS_TAGS.append(' '.join(temp))\n",
        "  else:\n",
        "    POS_TAGS.append(' '.join(temp))\n",
        "\n",
        "\n",
        "df_train['sents'].apply(lambda x: get_tag(x))\n",
        "df_val['sents'].apply(lambda x: get_tag(x,POS='Val'))\n",
        "df_test['sents'].apply(lambda x: get_tag(x,POS='Test'))\n",
        "print(f\"(First Sentence --> correspoding POS Tags: {POS_TAGS[0]})\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(First Sentence --> correspoding POS Tags: NN NN NN ( JJ : JJ NNP NNP NNP NNP NNP NNP NNP NNP NNP NNP NNP NNP NNP VBZ PRP$ NN ) VBD DT JJ NN VBN IN NN NNS IN JJ NN CD TO VB DT NN IN JJ NNS VBG DT NN CC VBG DT JJ NN .)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "jWNafAqkrGKz",
        "outputId": "53bcfec8-f870-4cc5-ff2a-b04249f3db10"
      },
      "source": [
        "df_new_val=pd.DataFrame({'sentences':val_sentences,'NER_Tags':val_labels,'POS_Tags':val_POS_TAGS})   #,'Dependency_parsing':D_Tags})\n",
        "df_new_val.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>NER_Tags</th>\n",
              "      <th>POS_Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>for 14 - year - old amjad it is safer there th...</td>\n",
              "      <td>O B-Quantity I-Quantity I-Quantity I-Quantity ...</td>\n",
              "      <td>IN CD : NN : JJ NN PRP VBZ JJR RB IN VBG IN NN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>. near al huwayjah , one strike engaged an isi...</td>\n",
              "      <td>O O B-Location I-Location O B-Quantity B-Weapo...</td>\n",
              "      <td>. IN JJ NN , CD NN VBD DT JJ JJ NN CC VBD DT J...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>philip hammond condemns apparent barrel bomb a...</td>\n",
              "      <td>B-Person I-Person O O B-Weapon I-Weapon O O B-...</td>\n",
              "      <td>NN NN NN JJ NN NN NNS IN NN WDT VBP VBN CC VBN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>foreign secretary boris johnson welcomes the u...</td>\n",
              "      <td>B-Person I-Person I-Person I-Person O O B-Docu...</td>\n",
              "      <td>JJ NN VBD JJ VBZ DT JJ NN IN NN NNP VBD JJ IN ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sadiq stood behind karim when the musician pla...</td>\n",
              "      <td>B-Person O O B-Person O B-Person I-Person O O ...</td>\n",
              "      <td>NN VBD IN NN WRB DT JJ VBD DT NN PRP '' NN VBD...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentences  ...                                           POS_Tags\n",
              "0  for 14 - year - old amjad it is safer there th...  ...  IN CD : NN : JJ NN PRP VBZ JJR RB IN VBG IN NN...\n",
              "1  . near al huwayjah , one strike engaged an isi...  ...  . IN JJ NN , CD NN VBD DT JJ JJ NN CC VBD DT J...\n",
              "2  philip hammond condemns apparent barrel bomb a...  ...  NN NN NN JJ NN NN NNS IN NN WDT VBP VBN CC VBN...\n",
              "3  foreign secretary boris johnson welcomes the u...  ...  JJ NN VBD JJ VBZ DT JJ NN IN NN NNP VBD JJ IN ...\n",
              "4  sadiq stood behind karim when the musician pla...  ...  NN VBD IN NN WRB DT JJ VBD DT NN PRP '' NN VBD...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNsqjyhpEdQi"
      },
      "source": [
        "# for i in range(len(test_sentences)):\n",
        "#   temp=test_sentences[i].split()\n",
        "#   pos=test_POS_TAGS[i].split()\n",
        "#   # lab=val_labels[i].split()\n",
        "#   if(len(temp)!= len(pos)):\n",
        "#     print(f\"For sentence number {i} : words: {len(temp)}  | pos: {len(pos)} \")# | NER: {len(lab)}\")\n",
        "#     # print(f\" second last tag: {pos[-1]}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "wMshsvxWrIWV",
        "outputId": "6822d91e-c775-4b1f-de43-15c737af5402"
      },
      "source": [
        "df_new_test=pd.DataFrame({'sentences':test_sentences,'POS_Tags':test_POS_TAGS})   #,'Dependency_parsing':D_Tags})\n",
        "df_new_test.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>POS_Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>carter thanked abadi for nearly two years of a...</td>\n",
              "      <td>NN VBD NN IN RB CD NNS IN DT JJ JJ NN , CC VBD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>analyses performed by the hospital lab include...</td>\n",
              "      <td>NNS VBN IN DT NN NN VBP JJ , JJ , NN , JJ , CC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the last meeting of the small group took place...</td>\n",
              "      <td>DT JJ NN IN DT JJ NN VBD NN IN NN , NN . NN . ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\" \" \" as we meet here , we are hoping to gener...</td>\n",
              "      <td>JJ NNP NNP IN PRP VBP RB , PRP VBP VBG TO VB D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>one jet bombed a school for girls in a souther...</td>\n",
              "      <td>CD NN VBD DT NN IN NNS IN DT JJ NN IN DT NN IN...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentences                                           POS_Tags\n",
              "0  carter thanked abadi for nearly two years of a...  NN VBD NN IN RB CD NNS IN DT JJ JJ NN , CC VBD...\n",
              "1  analyses performed by the hospital lab include...  NNS VBN IN DT NN NN VBP JJ , JJ , NN , JJ , CC...\n",
              "2  the last meeting of the small group took place...  DT JJ NN IN DT JJ NN VBD NN IN NN , NN . NN . ...\n",
              "3  \" \" \" as we meet here , we are hoping to gener...  JJ NNP NNP IN PRP VBP RB , PRP VBP VBG TO VB D...\n",
              "4  one jet bombed a school for girls in a souther...  CD NN VBD DT NN IN NNS IN DT JJ NN IN DT NN IN..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYkyy16vxSJz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4099cc09-ffe4-47de-b910-c31521c9b08f"
      },
      "source": [
        "#len(POS_TAGS)== len(sentences)\n",
        "#Creating a new dataframe with POS TAGS, Sentences and NER Tags\n",
        "df_new_train=pd.DataFrame({'sentences':sentences,'NER_Tags':labels,'POS_Tags':POS_TAGS})   #,'Dependency_parsing':D_Tags})\n",
        "df_new_train.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>NER_Tags</th>\n",
              "      <th>POS_Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>operation steel curtain ( arabic : ا ل ح ج ا ب...</td>\n",
              "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
              "      <td>NN NN NN ( JJ : JJ NNP NNP NNP NNP NNP NNP NNP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the hospital has facilities for mri and ct sca...</td>\n",
              "      <td>B-Location I-Location O O O O O O O O O O O O ...</td>\n",
              "      <td>DT NN VBZ NNS IN NN CC JJ NN , DT NN NN CC JJ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the operation was important in that it was the...</td>\n",
              "      <td>O O O O O O O O O O O O O O B-Organisation I-O...</td>\n",
              "      <td>DT NN VBD JJ IN DT PRP VBD DT JJ JJ JJ NN IN D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this was my first visit to uzbekistan and an i...</td>\n",
              "      <td>O O B-Person O O O B-Location O O O O O O O O ...</td>\n",
              "      <td>DT VBD PRP$ JJ NN TO VB CC DT JJ NN TO VB CC V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the group was founded by sheikh abu omar al - ...</td>\n",
              "      <td>B-Organisation I-Organisation O O O B-Person I...</td>\n",
              "      <td>DT NN VBD VBN IN JJ JJ NN SYM : NN . NN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentences  ...                                           POS_Tags\n",
              "0  operation steel curtain ( arabic : ا ل ح ج ا ب...  ...  NN NN NN ( JJ : JJ NNP NNP NNP NNP NNP NNP NNP...\n",
              "1  the hospital has facilities for mri and ct sca...  ...  DT NN VBZ NNS IN NN CC JJ NN , DT NN NN CC JJ ...\n",
              "2  the operation was important in that it was the...  ...  DT NN VBD JJ IN DT PRP VBD DT JJ JJ JJ NN IN D...\n",
              "3  this was my first visit to uzbekistan and an i...  ...  DT VBD PRP$ JJ NN TO VB CC DT JJ NN TO VB CC V...\n",
              "4  the group was founded by sheikh abu omar al - ...  ...            DT NN VBD VBN IN JJ JJ NN SYM : NN . NN\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qev_vKX3taUN"
      },
      "source": [
        "## words, Tags to index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixtTKXM9bZDD"
      },
      "source": [
        "#Referred to Lab 9 code\n",
        "#word to index\n",
        "word_to_ix = {}\n",
        "for sentence in sentences+val_sentences+test_sentences:\n",
        "    for word in sentence.split():\n",
        "      word = word.lower()\n",
        "      if word not in word_to_ix:\n",
        "        word_to_ix[word] = len(word_to_ix)\n",
        "word_list = list(word_to_ix.keys())\n",
        "\n",
        "#Tags to index\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix = {START_TAG:0, STOP_TAG:1}\n",
        "for tags in labels+val_labels:\n",
        "    for tag in tags.split():\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)\n",
        "\n",
        "#POS Tags to index\n",
        "pos_tag_to_ix={}\n",
        "for tags in POS_TAGS+val_POS_TAGS+test_POS_TAGS:\n",
        "    for tag in tags.split():\n",
        "        if tag not in pos_tag_to_ix: # and tag not in (\"''\",'``','$',',','.',':'):\n",
        "            pos_tag_to_ix[tag] = len(pos_tag_to_ix)\n",
        "\n",
        "# #Dependency Tags to index\n",
        "# dp_tag_to_ix={}\n",
        "# for tags in D_Tags:\n",
        "#     for tag in nltk.word_tokenize(tags):\n",
        "#         if tag not in dp_tag_to_ix:\n",
        "#             dp_tag_to_ix[tag] = len(dp_tag_to_ix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6grm7bwntuiv"
      },
      "source": [
        "### Glove Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D72G8SNpwcxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2309c77c-f5fe-4fed-d593-f29f80a02f8e"
      },
      "source": [
        "#load pretrained model\n",
        "import gensim.downloader as api\n",
        "word_emb_model = api.load(\"glove-twitter-25\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIO6Y86DlO2n",
        "outputId": "3bd9e6e5-63fc-40b4-bd69-dc6e671882b3"
      },
      "source": [
        "#Embedding matrix\n",
        "# Referred to Lab 9 code\n",
        "EMBEDDING_DIM = 25\n",
        "\n",
        "embedding_matrix = []\n",
        "for word in word_list:\n",
        "    try:\n",
        "        embedding_matrix.append(word_emb_model.wv[word])\n",
        "    except:\n",
        "        embedding_matrix.append([0]*EMBEDDING_DIM)\n",
        "embedding_matrix = np.array(embedding_matrix)\n",
        "embedding_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.54109001,  0.57410002, -0.57692999, ...,  0.28832   ,\n",
              "        -0.95007998,  0.07306   ],\n",
              "       [-0.70985001, -0.67839998,  0.1409    , ...,  1.13320005,\n",
              "         0.30127001,  0.024852  ],\n",
              "       [-1.22759998, -0.54803002,  1.18970001, ...,  1.63769996,\n",
              "        -0.13262001, -0.45129001],\n",
              "       ...,\n",
              "       [-0.94571   ,  0.62142998, -0.28505999, ..., -0.014275  ,\n",
              "        -0.17116   , -0.56494999],\n",
              "       [ 0.070695  ,  0.97428   , -0.82848001, ..., -1.16050005,\n",
              "        -0.38016999, -1.00199997],\n",
              "       [-0.24102999,  0.40322   , -0.37015   , ..., -0.19942001,\n",
              "        -0.74471998, -1.05780005]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7raVD1tvfv_H"
      },
      "source": [
        "# def prepare_sequence(seq, to_ix):\n",
        "#     idxs = [to_ix[w] for w in seq]\n",
        "#     return torch.tensor(idxs, dtype=torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOCBgunWfYDY"
      },
      "source": [
        "# sent_in=prepare_sequence(\"operation steel curtain\".split(),word_to_ix)\n",
        "# x(sent_in).view(len(sent_in),1,-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0XkunlLcpu1"
      },
      "source": [
        "## Data indexing for model input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT2TxZ5HleqN"
      },
      "source": [
        " #Referred from Lab 9 code\n",
        "#Convert data sets to indexes\n",
        "def to_index(data, to_ix):\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "      # if not flag:\n",
        "      input_index_list.append([to_ix[w] for w in sent.split()])\n",
        "      # else:\n",
        "      #   temp=sent.split()\n",
        "      #   input_index_list.append([to_ix[w] for w in temp])\n",
        "    return input_index_list\n",
        "\n",
        "#Training data\n",
        "train_input_index =  to_index(df_new_train['sentences'],word_to_ix)\n",
        "train_output_index = to_index(df_new_train['NER_Tags'],tag_to_ix)\n",
        "train_pos_index = to_index(df_new_train['POS_Tags'],pos_tag_to_ix)\n",
        "\n",
        "#Validation data\n",
        "val_input_index = to_index(df_new_val['sentences'],word_to_ix)\n",
        "val_output_index = to_index(df_new_val['NER_Tags'],tag_to_ix)\n",
        "val_pos_index = to_index(df_new_val['POS_Tags'],pos_tag_to_ix)\n",
        "\n",
        "#test data\n",
        "test_input_index = to_index(df_new_test['sentences'],word_to_ix)\n",
        "test_pos_index = to_index(df_new_test['POS_Tags'],pos_tag_to_ix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNtlkS-rcwq_"
      },
      "source": [
        "# Bi-Lstm with CRF Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWOhREFUxXT-"
      },
      "source": [
        "#Referred from Lab 9 code\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim,hidden_dim,pos_size=None,pos_tag_dim=None,no_layers=1,attention_type=None):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.nl=no_layers\n",
        "        self.attention=attention_type\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "\n",
        "        if pos_size is not None:\n",
        "          self.pos_embeds=nn.Embedding(pos_size,pos_tag_dim)\n",
        "          self.lstm = nn.LSTM(embedding_dim+pos_tag_dim, hidden_dim // 2,\n",
        "                              num_layers=self.nl, bidirectional=True)\n",
        "        else:\n",
        "          self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                              num_layers=self.nl, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        if self.attention is None:\n",
        "          self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "        else:\n",
        "          self.hidden2tag = nn.Linear(hidden_dim*2, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        # self.hidden =  nn.init.xavier_uniform(self.hidden2tag.weight)\n",
        "        self.hidden=self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2 * self.nl, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2 * self.nl, 1, self.hidden_dim // 2).to(device))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence,pos_tags=None):\n",
        "      # try:\n",
        "        embeds = []\n",
        "        self.hidden = self.init_hidden()\n",
        "        w_embeds = self.word_embeds(sentence)#.view(len(sentence), 1, -1)\n",
        "\n",
        "        #check the embeding inputs and get vectors\n",
        "        if pos_tags is not None:  #USes POS Tags and Word2Vec embedding\n",
        "          p_embeds = self.pos_embeds(pos_tags)#.view(len(pos_tags),1,-1)\n",
        "          embeds=torch.cat((w_embeds,p_embeds),1)\n",
        "          embeds=embeds.view(len(embeds),1,-1)\n",
        "\n",
        "        #only Word2Vec embedding\n",
        "        else:\n",
        "           embeds=w_embeds.view(len(w_embeds),1,-1)\n",
        "\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "\n",
        "        if self.attention is not None:\n",
        "          lstm_out = self.calc_attention(lstm_out)\n",
        "\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags,pos_tags=None):\n",
        "        feats = self._get_lstm_features(sentence,pos_tags)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence,pos_tags=None):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence,pos_tags)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq\n",
        "\n",
        "    def calc_attention(self,h_states):\n",
        "\n",
        "      if self.attention == \"dot\":\n",
        "        score=h_states @ h_states.permute(1,0)\n",
        "      elif self.attention == \"scale\":\n",
        "        hidden_size = h_states.size(1)\n",
        "        score=(1/(np.sqrt(hidden_size))*(h_states @ h_states.permute(1,0)))\n",
        "      score=F.softmax(score,-1)\n",
        "      res = score @ h_states\n",
        "      return torch.cat([res,h_states],-1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTLrhIxWcjPK"
      },
      "source": [
        "# Accuracy Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f--yhBeNv7Ok"
      },
      "source": [
        "#function to calculate accuracy\n",
        "#Referred from Lab 9 code\n",
        "def cal_acc(model, input_index, output_index,pos_index=None):\n",
        "    ground_truth = []\n",
        "    predicted = []\n",
        "    for i,idxs in enumerate(input_index):\n",
        "        ground_truth += output_index[i]\n",
        "        if pos_index is not None:\n",
        "          score, pred = model(torch.tensor(idxs,dtype=torch.long).to(device),torch.tensor(pos_index[i],dtype=torch.long).to(device))\n",
        "        else:\n",
        "          score, pred = model(torch.tensor(idxs,dtype=torch.long).to(device).to(device))\n",
        "        predicted += pred\n",
        "    accuracy = sum(np.array(ground_truth) == np.array(predicted))/len(ground_truth)\n",
        "    return predicted, ground_truth, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_Q-nJTVb8gq"
      },
      "source": [
        "# Bi-LSTM with CRF and input embedding (glove + POS Tags)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNrJ9Vn6mLVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a1c717-5a53-4a0c-a6c5-9367904e27eb"
      },
      "source": [
        "#hyperparameters\n",
        "#Referred from Lab 9 code\n",
        "START_TAG = \"<START>\"  #start of sequence\n",
        "STOP_TAG = \"<STOP>\"    #end of seqeuence\n",
        "EMBEDDING_DIM = 25     #embedding dimension\n",
        "HIDDEN_DIM = 4          #hidden dimenisom\n",
        "pos_tag_dim=3         #embedding dimnsion for POS TAG\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# (self, vocab_size,pos_size, tag_to_ix, embedding_dim,pos_tag_dim, hidden_dim):\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, len(pos_tag_to_ix), pos_tag_dim).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "\n",
        "for epoch in range(20):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "        pos_index=train_pos_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        pos_in_tags = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos_in_tags)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        pos_index=val_pos_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        pos_in_tags = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos_in_tags)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}, Training loss: {train_loss:.2f}, train acc:{train_acc:.4f} , val loss: {val_loss:.2f}, val acc: {val_acc:.2f},time:{(time2-time1).total_seconds()}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training loss: 16368.24, train acc:0.7024 , val loss: 5191.54, val acc: 0.65,time:182.553055\n",
            "Epoch: 2, Training loss: 10836.26, train acc:0.7296 , val loss: 4381.56, val acc: 0.67,time:182.917488\n",
            "Epoch: 3, Training loss: 9240.30, train acc:0.7408 , val loss: 3978.03, val acc: 0.68,time:182.128889\n",
            "Epoch: 4, Training loss: 8297.37, train acc:0.7656 , val loss: 3676.84, val acc: 0.71,time:179.73226\n",
            "Epoch: 5, Training loss: 7628.15, train acc:0.7839 , val loss: 3486.84, val acc: 0.72,time:179.240387\n",
            "Epoch: 6, Training loss: 7113.49, train acc:0.7898 , val loss: 3317.24, val acc: 0.73,time:178.94828\n",
            "Epoch: 7, Training loss: 6709.05, train acc:0.7943 , val loss: 3206.83, val acc: 0.73,time:178.764359\n",
            "Epoch: 8, Training loss: 6376.26, train acc:0.7990 , val loss: 3109.42, val acc: 0.74,time:179.008932\n",
            "Epoch: 9, Training loss: 6098.95, train acc:0.8044 , val loss: 3020.90, val acc: 0.74,time:178.898362\n",
            "Epoch: 10, Training loss: 5858.50, train acc:0.8082 , val loss: 2956.98, val acc: 0.74,time:178.829415\n",
            "Epoch: 11, Training loss: 5617.17, train acc:0.8122 , val loss: 2916.32, val acc: 0.75,time:178.960615\n",
            "Epoch: 12, Training loss: 5420.47, train acc:0.8176 , val loss: 2858.12, val acc: 0.75,time:179.55277\n",
            "Epoch: 13, Training loss: 5231.55, train acc:0.8238 , val loss: 2827.87, val acc: 0.76,time:178.035716\n",
            "Epoch: 14, Training loss: 5043.15, train acc:0.8277 , val loss: 2800.47, val acc: 0.76,time:179.789365\n",
            "Epoch: 15, Training loss: 4882.97, train acc:0.8342 , val loss: 2774.10, val acc: 0.76,time:179.539478\n",
            "Epoch: 16, Training loss: 4752.54, train acc:0.8392 , val loss: 2747.21, val acc: 0.76,time:178.975088\n",
            "Epoch: 17, Training loss: 4589.07, train acc:0.8459 , val loss: 2741.52, val acc: 0.77,time:180.393779\n",
            "Epoch: 18, Training loss: 4466.41, train acc:0.8490 , val loss: 2714.35, val acc: 0.77,time:182.341559\n",
            "Epoch: 19, Training loss: 4318.20, train acc:0.8561 , val loss: 2699.03, val acc: 0.77,time:179.878121\n",
            "Epoch: 20, Training loss: 4159.33, train acc:0.8590 , val loss: 2678.10, val acc: 0.78,time:176.460017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s-Pk1Iwkp2i",
        "outputId": "c930c5c6-cca3-4744-bdbc-15911755c7ac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/Kaggle/model.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBIqjQiGIiGN"
      },
      "source": [
        "predicted=[]\n",
        "for i,idxs in enumerate(test_input_index):\n",
        "  score, pred = model(torch.tensor(idxs,dtype=torch.long).to(device),torch.tensor(test_pos_index[i],dtype=torch.long).to(device))\n",
        "  predicted.append(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StO8FKGvIs6s",
        "outputId": "1fd4988e-c614-427a-9af9-7d57f7bbf76a"
      },
      "source": [
        "len(predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LNpMMXf_Bwb"
      },
      "source": [
        "predicted=[]\n",
        "for i,idxs in enumerate(test_input_index):\n",
        "        score, pred = model(torch.tensor(idxs,dtype=torch.long).to(device),torch.tensor(test_pos_index[i],dtype=torch.long).to(device))\n",
        "        predicted += pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIhqJZLuLDSB"
      },
      "source": [
        "df_temp=pd.DataFrame({'Predicted':predicted})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ4TERa4DbOy"
      },
      "source": [
        "# df_test_pred=pd.DataFrame({'sentences':test_sentences,'POS_Tags':test_POS_TAGS,'NER_Tags':predicted})   #,'Dependency_parsing':D_Tags})\n",
        "# df_test_pred.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfu7msGdI3x9"
      },
      "source": [
        "predicted=[]\n",
        "for i,idxs in enumerate(test_input_index):\n",
        "  score, pred = model(torch.tensor(idxs,dtype=torch.long).to(device),torch.tensor(test_pos_index[i],dtype=torch.long).to(device))\n",
        "  pred_labels=[]\n",
        "  for preds in pred:\n",
        "    for k,v in tag_to_ix.items():\n",
        "      if v==preds:\n",
        "        pred_labels.append(k)\n",
        "  predicted.append(' '.join(pred_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGnC5ZyxACJ_"
      },
      "source": [
        "df_temp.to_csv(\"/content/drive/MyDrive/Kaggle/predicted.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOnJrtGjbMUZ"
      },
      "source": [
        "# Bi-LSTM with CRF and input embedding (glove)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5l3ssz1bLa3",
        "outputId": "cff792df-f4bd-4020-991f-fa9edae00521"
      },
      "source": [
        "#Referred from Lab 9 code\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "EMBEDDING_DIM = 25\n",
        "HIDDEN_DIM = 4\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# (self, vocab_size,pos_size, tag_to_ix, embedding_dim,pos_tag_dim, hidden_dim):\n",
        "model = BiLSTM_CRF(len(word_to_ix),tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "for epoch in range(10):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        pos_index=val_pos_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}, Training loss: {train_loss:.2f}, train acc:{train_acc:.4f} , val loss: {val_loss:.2f}, val acc: {val_acc:.2f},time:{(time2-time1).total_seconds()}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training loss: 16591.57, train acc:0.7067 , val loss: 5431.45, val acc: 0.65,time:180.24766\n",
            "Epoch: 2, Training loss: 11580.35, train acc:0.7371 , val loss: 4574.84, val acc: 0.69,time:179.853611\n",
            "Epoch: 3, Training loss: 9725.46, train acc:0.7594 , val loss: 4000.61, val acc: 0.71,time:179.499641\n",
            "Epoch: 4, Training loss: 8496.96, train acc:0.7755 , val loss: 3660.18, val acc: 0.73,time:179.176019\n",
            "Epoch: 5, Training loss: 7621.58, train acc:0.7860 , val loss: 3410.30, val acc: 0.73,time:180.74654\n",
            "Epoch: 6, Training loss: 6944.95, train acc:0.7975 , val loss: 3220.17, val acc: 0.74,time:180.384671\n",
            "Epoch: 7, Training loss: 6387.85, train acc:0.8082 , val loss: 3058.34, val acc: 0.75,time:180.911764\n",
            "Epoch: 8, Training loss: 5908.08, train acc:0.8195 , val loss: 2923.17, val acc: 0.75,time:178.880586\n",
            "Epoch: 9, Training loss: 5479.12, train acc:0.8279 , val loss: 2811.28, val acc: 0.76,time:179.313529\n",
            "Epoch: 10, Training loss: 5126.69, train acc:0.8359 , val loss: 2728.98, val acc: 0.76,time:179.120968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY_J3RFWujFm"
      },
      "source": [
        "# Stacked BiLSTM with CRF and input embedding (POS Tags + glove)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8fVNIrZurGN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "641323de-5736-46d1-9efd-cfb2a6240cd9"
      },
      "source": [
        "#Referred from Lab 9 code\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "EMBEDDING_DIM = 25\n",
        "HIDDEN_DIM = 4\n",
        "pos_tag_dim=3\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# (self, vocab_size,pos_size, tag_to_ix, embedding_dim,pos_tag_dim, hidden_dim):\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, len(pos_tag_to_ix), pos_tag_dim,2).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "for epoch in range(10):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "        pos_index=train_pos_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        pos_in_tags = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos_in_tags)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index)\n",
        "\n",
        "    # val_loss = 0\n",
        "    # for i, idxs in enumerate(val_input_index):\n",
        "    #     tags_index = val_output_index[i]\n",
        "    #     pos_index=val_pos_index[i]\n",
        "    #     sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "    #     targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "    #     pos_in_tags = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "    #     loss = model.neg_log_likelihood(sentence_in, targets,pos_in_tags)\n",
        "    #     val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}, Training loss: {train_loss:.2f}, train acc:{train_acc:.4f} , val acc: {val_acc:.2f},time:{(time2-time1).total_seconds()}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training loss: 16566.47, train acc:0.7061 , val acc: 0.65,time:163.516722\n",
            "Epoch: 2, Training loss: 10821.95, train acc:0.7187 , val acc: 0.66,time:163.501244\n",
            "Epoch: 3, Training loss: 9367.29, train acc:0.7323 , val acc: 0.68,time:163.718022\n",
            "Epoch: 4, Training loss: 8609.73, train acc:0.7271 , val acc: 0.68,time:166.244779\n",
            "Epoch: 5, Training loss: 8105.54, train acc:0.7498 , val acc: 0.69,time:167.125295\n",
            "Epoch: 6, Training loss: 7697.43, train acc:0.7434 , val acc: 0.69,time:167.048024\n",
            "Epoch: 7, Training loss: 7394.33, train acc:0.7534 , val acc: 0.70,time:167.391112\n",
            "Epoch: 8, Training loss: 7151.09, train acc:0.7597 , val acc: 0.70,time:166.877377\n",
            "Epoch: 9, Training loss: 6846.31, train acc:0.7613 , val acc: 0.70,time:167.275137\n",
            "Epoch: 10, Training loss: 6594.59, train acc:0.7664 , val acc: 0.71,time:166.934262\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yM6mkpH3Wgu"
      },
      "source": [
        "# Stacked BiLSTM with CRF and input embedding (glove)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evThCYy63dp_",
        "outputId": "a31b4712-9ef6-4d75-a069-10a666d56248"
      },
      "source": [
        "#Referred from Lab 9 code\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "EMBEDDING_DIM = 25\n",
        "HIDDEN_DIM = 4\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# (self, vocab_size,pos_size, tag_to_ix, embedding_dim,pos_tag_dim, hidden_dim):\n",
        "model = BiLSTM_CRF(len(word_to_ix),tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,no_layers=2).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "\n",
        "for epoch in range(10):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index)\n",
        "\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}, Training loss: {train_loss:.2f}, train acc:{train_acc:.4f}, val acc: {val_acc:.2f},time:{(time2-time1).total_seconds()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training loss: 16516.75, train acc:0.7005, val acc: 0.65,time:166.395732\n",
            "Epoch: 2, Training loss: 11947.01, train acc:0.7076, val acc: 0.66,time:166.956011\n",
            "Epoch: 3, Training loss: 10147.21, train acc:0.7202, val acc: 0.66,time:166.749587\n",
            "Epoch: 4, Training loss: 9112.02, train acc:0.7290, val acc: 0.67,time:166.729283\n",
            "Epoch: 5, Training loss: 8449.77, train acc:0.7333, val acc: 0.68,time:167.066695\n",
            "Epoch: 6, Training loss: 8016.83, train acc:0.7359, val acc: 0.68,time:166.687942\n",
            "Epoch: 7, Training loss: 7632.13, train acc:0.7423, val acc: 0.69,time:166.95171\n",
            "Epoch: 8, Training loss: 7268.78, train acc:0.7488, val acc: 0.69,time:166.787103\n",
            "Epoch: 9, Training loss: 6936.15, train acc:0.7594, val acc: 0.71,time:167.573243\n",
            "Epoch: 10, Training loss: 6587.86, train acc:0.7709, val acc: 0.72,time:167.834641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKqnw1Jjpt4M"
      },
      "source": [
        "# Bi-LSTM with CRF and Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaRfF9c8qLGM"
      },
      "source": [
        "## Attention Type: DOT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXDqkDct5gdu"
      },
      "source": [
        "### Stacked Bi-LSTM model with CRF,Attention and input embeddings (POS Tags+glove)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lGE0TmG5ogV",
        "outputId": "f1ae77fb-55df-476d-f582-6072f07b7c33"
      },
      "source": [
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "EMBEDDING_DIM = 25\n",
        "HIDDEN_DIM = 4\n",
        "pos_tag_dim=3\n",
        "att_type='dot'\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# (self, vocab_size,pos_size, tag_to_ix, embedding_dim,pos_tag_dim, hidden_dim):\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, len(pos_tag_to_ix), pos_tag_dim,no_layers=2,attention_type=att_type).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "for epoch in range(10):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "        pos_index=train_pos_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        pos_in_tags = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos_in_tags)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index)\n",
        "\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}, Training loss: {train_loss:.2f}, train acc:{train_acc:.4f} , val acc: {val_acc:.2f},time:{(time2-time1).total_seconds()}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training loss: 17275.02, train acc:0.6999 , val acc: 0.65,time:268.153363\n",
            "Epoch: 2, Training loss: 11655.80, train acc:0.7204 , val acc: 0.67,time:269.259289\n",
            "Epoch: 3, Training loss: 9623.13, train acc:0.7275 , val acc: 0.67,time:264.292492\n",
            "Epoch: 4, Training loss: 8673.70, train acc:0.7326 , val acc: 0.68,time:262.468029\n",
            "Epoch: 5, Training loss: 8100.32, train acc:0.7441 , val acc: 0.70,time:261.089967\n",
            "Epoch: 6, Training loss: 7640.14, train acc:0.7521 , val acc: 0.70,time:262.002614\n",
            "Epoch: 7, Training loss: 7325.76, train acc:0.7584 , val acc: 0.70,time:263.529343\n",
            "Epoch: 8, Training loss: 7057.94, train acc:0.7601 , val acc: 0.70,time:266.50174\n",
            "Epoch: 9, Training loss: 6855.13, train acc:0.7635 , val acc: 0.71,time:259.686278\n",
            "Epoch: 10, Training loss: 6618.14, train acc:0.7673 , val acc: 0.71,time:258.898479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L_TUKeJfNtS"
      },
      "source": [
        "### Bi-LSTM model with CRF,Attention and input embedding (POS Tags+glove)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Shhr8rwIfYE2",
        "outputId": "cd9b7428-3cce-43ae-dfb1-b40085fc05b3"
      },
      "source": [
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "EMBEDDING_DIM = 25\n",
        "HIDDEN_DIM = 4\n",
        "pos_tag_dim=3\n",
        "att_type='dot'\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# (self, vocab_size,pos_size, tag_to_ix, embedding_dim,pos_tag_dim, hidden_dim):\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, len(pos_tag_to_ix), pos_tag_dim,no_layers=1,attention_type=att_type).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "for epoch in range(10):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "        pos_index=train_pos_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        pos_in_tags = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos_in_tags)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index)\n",
        "\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}, Training loss: {train_loss:.2f}, train acc:{train_acc:.4f} , val acc: {val_acc:.2f},time:{(time2-time1).total_seconds()}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training loss: 14651.37, train acc:0.7028 , val acc: 0.65,time:256.190524\n",
            "Epoch: 2, Training loss: 10112.44, train acc:0.7362 , val acc: 0.68,time:258.07783\n",
            "Epoch: 3, Training loss: 8548.32, train acc:0.7548 , val acc: 0.70,time:255.028611\n",
            "Epoch: 4, Training loss: 7629.00, train acc:0.7649 , val acc: 0.71,time:252.840872\n",
            "Epoch: 5, Training loss: 7034.17, train acc:0.7724 , val acc: 0.72,time:254.58089\n",
            "Epoch: 6, Training loss: 6589.37, train acc:0.7861 , val acc: 0.74,time:253.188719\n",
            "Epoch: 7, Training loss: 6231.56, train acc:0.8004 , val acc: 0.74,time:253.73631\n",
            "Epoch: 8, Training loss: 5913.54, train acc:0.8061 , val acc: 0.75,time:259.929436\n",
            "Epoch: 9, Training loss: 5609.84, train acc:0.8192 , val acc: 0.76,time:256.064089\n",
            "Epoch: 10, Training loss: 5341.36, train acc:0.8272 , val acc: 0.77,time:258.234387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTgoup3IpXMu"
      },
      "source": [
        "### Bi-LSTM Model with CRF,Attention and input embedding (glove)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1OCSB7ophI9",
        "outputId": "f3d05787-41a0-440b-80fd-36b7b34438b1"
      },
      "source": [
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "EMBEDDING_DIM = 25\n",
        "HIDDEN_DIM = 4\n",
        "att_type='dot'\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# (self, vocab_size,pos_size, tag_to_ix, embedding_dim,pos_tag_dim, hidden_dim):\n",
        "model = BiLSTM_CRF(len(word_to_ix),tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,attention_type=att_type).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "for epoch in range(10):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index)\n",
        "\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}, Training loss: {train_loss:.2f}, train acc:{train_acc:.4f} , val acc: {val_acc:.2f},time:{(time2-time1).total_seconds()}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training loss: 16375.66, train acc:0.6924 , val acc: 0.64,time:255.623344\n",
            "Epoch: 2, Training loss: 10874.36, train acc:0.7172 , val acc: 0.66,time:256.409445\n",
            "Epoch: 3, Training loss: 9286.71, train acc:0.7398 , val acc: 0.69,time:260.854605\n",
            "Epoch: 4, Training loss: 8413.88, train acc:0.7574 , val acc: 0.70,time:261.739738\n",
            "Epoch: 5, Training loss: 7753.25, train acc:0.7753 , val acc: 0.72,time:261.79014\n",
            "Epoch: 6, Training loss: 7198.57, train acc:0.7866 , val acc: 0.73,time:260.924557\n",
            "Epoch: 7, Training loss: 6734.81, train acc:0.7945 , val acc: 0.73,time:259.544075\n",
            "Epoch: 8, Training loss: 6382.16, train acc:0.8014 , val acc: 0.74,time:257.833037\n",
            "Epoch: 9, Training loss: 6057.28, train acc:0.8064 , val acc: 0.75,time:257.937455\n",
            "Epoch: 10, Training loss: 5784.95, train acc:0.8107 , val acc: 0.75,time:257.204434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLVDK0vQ28Du"
      },
      "source": [
        "## Attention Type:Scale Dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fV3FBts3Mj_"
      },
      "source": [
        "###  Bi-LSTM model with CRF,Attention and input embedding (POS Tags+glove)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z5n5vun3Csg",
        "outputId": "50d1704e-c56d-4be4-bdca-a9a1f9f0667e"
      },
      "source": [
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "EMBEDDING_DIM = 25\n",
        "HIDDEN_DIM = 4\n",
        "pos_tag_dim=3\n",
        "att_type='scale'\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# (self, vocab_size,pos_size, tag_to_ix, embedding_dim,pos_tag_dim, hidden_dim):\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, len(pos_tag_to_ix), pos_tag_dim,no_layers=1,attention_type=att_type).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "for epoch in range(10):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "        pos_index=train_pos_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        pos_in_tags = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos_in_tags)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index)\n",
        "\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}, Training loss: {train_loss:.2f}, train acc:{train_acc:.4f} , val acc: {val_acc:.2f},time:{(time2-time1).total_seconds()}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training loss: 16357.44, train acc:0.7164 , val acc: 0.66,time:251.057102\n",
            "Epoch: 2, Training loss: 10495.47, train acc:0.7482 , val acc: 0.69,time:255.417913\n",
            "Epoch: 3, Training loss: 8697.47, train acc:0.7739 , val acc: 0.71,time:256.442811\n",
            "Epoch: 4, Training loss: 7685.25, train acc:0.7878 , val acc: 0.72,time:257.441496\n",
            "Epoch: 5, Training loss: 7008.07, train acc:0.7946 , val acc: 0.73,time:257.473708\n",
            "Epoch: 6, Training loss: 6471.45, train acc:0.8040 , val acc: 0.74,time:256.986616\n",
            "Epoch: 7, Training loss: 6031.34, train acc:0.8154 , val acc: 0.75,time:257.647965\n",
            "Epoch: 8, Training loss: 5670.63, train acc:0.8234 , val acc: 0.76,time:255.127641\n",
            "Epoch: 9, Training loss: 5393.67, train acc:0.8295 , val acc: 0.77,time:258.507399\n",
            "Epoch: 10, Training loss: 5126.78, train acc:0.8346 , val acc: 0.77,time:257.833186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o6tkYjBFSjt"
      },
      "source": [
        "### Bi-LSTM Model with CRF,Attention and input embedding (glove)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VggnYnjcFTDN",
        "outputId": "11bdf7ca-17e3-4b8b-d28e-fe623899b567"
      },
      "source": [
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "EMBEDDING_DIM = 25\n",
        "HIDDEN_DIM = 4\n",
        "att_type='scale'\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# (self, vocab_size,pos_size, tag_to_ix, embedding_dim,pos_tag_dim, hidden_dim):\n",
        "model = BiLSTM_CRF(len(word_to_ix),tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,attention_type=att_type).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "for epoch in range(10):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index)\n",
        "\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}, Training loss: {train_loss:.2f}, train acc:{train_acc:.4f} , val acc: {val_acc:.2f},time:{(time2-time1).total_seconds()}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training loss: 16211.36, train acc:0.7151 , val acc: 0.66,time:162.413853\n",
            "Epoch: 2, Training loss: 10794.68, train acc:0.7464 , val acc: 0.69,time:161.568904\n",
            "Epoch: 3, Training loss: 8978.60, train acc:0.7651 , val acc: 0.71,time:161.400286\n",
            "Epoch: 4, Training loss: 7959.25, train acc:0.7792 , val acc: 0.72,time:160.974011\n",
            "Epoch: 5, Training loss: 7235.35, train acc:0.7938 , val acc: 0.73,time:160.653991\n",
            "Epoch: 6, Training loss: 6600.03, train acc:0.8068 , val acc: 0.74,time:160.352876\n",
            "Epoch: 7, Training loss: 6113.62, train acc:0.8185 , val acc: 0.74,time:160.530104\n",
            "Epoch: 8, Training loss: 5685.13, train acc:0.8247 , val acc: 0.75,time:160.46274\n",
            "Epoch: 9, Training loss: 5351.48, train acc:0.8329 , val acc: 0.75,time:160.241223\n",
            "Epoch: 10, Training loss: 5066.29, train acc:0.8358 , val acc: 0.75,time:159.900378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVhF-V3yLAHY"
      },
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/Kaggle/Stacked-BiLSTM-CRF-ATT-Glove.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXuu8vloZQqo"
      },
      "source": [
        "### Stacked Bi-LSTM model with CRF,Attention and input embeddings (POS Tags+glove)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFOhTSoJZUm0",
        "outputId": "b8bf4ccc-15de-46e9-934e-fe1e2182a2b2"
      },
      "source": [
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "EMBEDDING_DIM = 25\n",
        "HIDDEN_DIM = 4\n",
        "pos_tag_dim=3\n",
        "att_type='scale'\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# (self, vocab_size,pos_size, tag_to_ix, embedding_dim,pos_tag_dim, hidden_dim):\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, len(pos_tag_to_ix), pos_tag_dim,no_layers=2,attention_type=att_type).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "\n",
        "for epoch in range(10):\n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "        pos_index=train_pos_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        pos_in_tags = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos_in_tags)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index)\n",
        "\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}, Training loss: {train_loss:.2f}, train acc:{train_acc:.4f} , val acc: {val_acc:.2f},time:{(time2-time1).total_seconds()}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training loss: 17559.44, train acc:0.7028 , val acc: 0.65,time:163.945229\n",
            "Epoch: 2, Training loss: 10801.32, train acc:0.7181 , val acc: 0.66,time:163.08931\n",
            "Epoch: 3, Training loss: 9189.30, train acc:0.7290 , val acc: 0.68,time:162.707555\n",
            "Epoch: 4, Training loss: 8388.87, train acc:0.7347 , val acc: 0.70,time:162.179478\n",
            "Epoch: 5, Training loss: 7859.09, train acc:0.7371 , val acc: 0.69,time:161.861113\n",
            "Epoch: 6, Training loss: 7487.66, train acc:0.7466 , val acc: 0.70,time:161.806712\n",
            "Epoch: 7, Training loss: 7194.48, train acc:0.7511 , val acc: 0.70,time:162.036358\n",
            "Epoch: 8, Training loss: 6927.87, train acc:0.7568 , val acc: 0.71,time:161.786919\n",
            "Epoch: 9, Training loss: 6725.54, train acc:0.7600 , val acc: 0.71,time:161.510896\n",
            "Epoch: 10, Training loss: 6475.68, train acc:0.7661 , val acc: 0.71,time:161.684695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuC74eEbEAy_",
        "outputId": "2fea8019-c119-4280-a2ce-96ee1b704bcf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/Kaggle/Stacked-BiLSTM-CRF-ATT-POS_Gl.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}